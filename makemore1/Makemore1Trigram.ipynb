{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ef0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e826e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt' , 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716cf170",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {}\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1 , ch2 , ch3 in zip(chs , chs[1:] , chs[2:]):\n",
    "        trigram = (ch1 , ch2 , ch3)\n",
    "        t[trigram] = t.get(trigram , 0 )+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30b6de92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6037"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sorted(t.items(), key=lambda kv : -kv[1]))\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a98dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27,27 , 27) , dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eac8118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "650a6138",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1 , ch2 , ch3 in zip(chs , chs[1:] , chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        N[(ix1 , ix2) , ix3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f228d778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
       "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
       "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = N[0,1].float()\n",
    "p /= p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "344c3836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "ix = torch.multinomial(p , num_samples=1 , replacement=True , generator=g).item()\n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28aad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27, 27])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = (N).float()\n",
    "P /= P.sum(1 , keepdim=True)\n",
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48e64d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cexzm.\n",
      "zoglkurkicqzktyhwmvmzimjttainrlkfukzkktda.\n",
      "sfcxvpubjtbhrmgotzx.\n",
      "iczixqctvujkwptedogkkjemkmmsidguenkbvgynywftbspmhwcivgbvtahlvsu.\n",
      "dsdxxblnwglhpyiw.\n",
      "igwnjwrpfdwipkwzkm.\n",
      "desu.\n",
      "firmt.\n",
      "gbiksjbquabsvoth.\n",
      "kuysxqevhcmrbxmcwyhrrjenvxmvpfkmwmghfvjzxobomysox.\n",
      "gbptjapxweegpfwhccfyzfvksiiqmvwbhmiwqmdgzqsamjhgamcxwmmk.\n",
      "iswcxfmbalcslhy.\n",
      "fpycvasvz.\n",
      "bqzazeunschck.\n",
      "wnkojuoxyvtvfiwksddugnkul.\n",
      "fuwfcgjz.\n",
      "abl.\n",
      "j.\n",
      "nuuutstofgqzubbo.\n",
      "rdubpknhmd.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for i in range(20):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    ix2=0\n",
    "    while True:\n",
    "        p = P[ix,ix2]\n",
    "        ix3 = torch.multinomial(p , num_samples = 1 , replacement=True , generator = g).item()\n",
    "        out.append(itos[ix3])\n",
    "        if ix3==0:\n",
    "            break\n",
    "\n",
    "        ix1 , ix2 = ix2 , ix3\n",
    "\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51c0fa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".em: 0.1276\n",
      "emm: 0.0294\n",
      "mma: 0.0160\n",
      "ma.: 0.2269\n",
      ".ol: 0.0811\n",
      "oli: 0.0560\n",
      "liv: 0.1278\n",
      "ivi: 0.0102\n",
      "via: 0.1896\n",
      "ia.: 0.1558\n",
      ".av: 0.3143\n",
      "ava: 0.0187\n",
      "va.: 0.1747\n"
     ]
    }
   ],
   "source": [
    "for w in words[:3]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2,ch3 in zip(chs , chs[1:] , chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        prob = P[ix1 , ix2 , ix3]\n",
    "        print(f'{ch1}{ch2}{ch3}: {prob:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a660d3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-564270.9375\n",
      "2.8773\n"
     ]
    }
   ],
   "source": [
    "logprob = 0\n",
    "n=0\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2,ch3 in zip(chs , chs[1:] , chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        prob = P[ix1 , ix2 , ix3]\n",
    "        n+=1\n",
    "        logprob += torch.log(prob)\n",
    "\n",
    "print(f'{logprob:.4f}')\n",
    "neg_log = -logprob\n",
    "print(f'{neg_log/n :.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd7582",
   "metadata": {},
   "source": [
    "**Neural Network Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3df305d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of examples:  196113\n"
     ]
    }
   ],
   "source": [
    "#creating a dataset\n",
    "xs , ys = [] , []\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2,ch3 in zip(chs , chs[1:] , chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        xs.append([ix1,ix2])\n",
    "        ys.append(ix3)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = len(xs)\n",
    "print(\"no of examples: \" , num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2bb45413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  5],\n",
       "        [ 5, 13],\n",
       "        [13, 13],\n",
       "        ...,\n",
       "        [26, 25],\n",
       "        [25, 26],\n",
       "        [26, 24]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "352f3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Hot Encoding \n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "48889ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs , num_classes=27).float()   \n",
    "xenc = xenc.view(xs.shape[0], -1)\n",
    "W = torch.randn((54,27))                         \n",
    "xenc @ W\n",
    "logits = xenc @ W \n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1 , keepdims=True)             \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "224d2596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "bigram example 1: .em (indexes 05,13)\n",
      "input to the neural net: [0, 5]\n",
      "output probabilities from the neural net: tensor([0.0016, 0.1472, 0.0121, 0.0096, 0.1285, 0.0216, 0.0095, 0.0788, 0.0063,\n",
      "        0.0224, 0.0106, 0.0148, 0.0019, 0.0141, 0.0104, 0.0922, 0.0067, 0.0058,\n",
      "        0.0050, 0.1280, 0.0051, 0.0075, 0.0375, 0.1142, 0.0035, 0.0246, 0.0805])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the the correct character: 0.014113913290202618\n",
      "log likelihood: -4.260594367980957\n",
      "negative log likelihood: 4.260594367980957\n",
      "--------\n",
      "bigram example 2: emm (indexes 513,13)\n",
      "input to the neural net: [5, 13]\n",
      "output probabilities from the neural net: tensor([0.0039, 0.0156, 0.0065, 0.0262, 0.0155, 0.1858, 0.0100, 0.0530, 0.0888,\n",
      "        0.0231, 0.0093, 0.0098, 0.0081, 0.0151, 0.0166, 0.0030, 0.0468, 0.0135,\n",
      "        0.0151, 0.0936, 0.0121, 0.0014, 0.0081, 0.0075, 0.2752, 0.0262, 0.0102])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the the correct character: 0.015105281956493855\n",
      "log likelihood: -4.192710876464844\n",
      "negative log likelihood: 4.192710876464844\n",
      "--------\n",
      "bigram example 3: mma (indexes 1313,1)\n",
      "input to the neural net: [13, 13]\n",
      "output probabilities from the neural net: tensor([0.0237, 0.0086, 0.0123, 0.0542, 0.0150, 0.3698, 0.0010, 0.0332, 0.0541,\n",
      "        0.0367, 0.0792, 0.0297, 0.0062, 0.0036, 0.0103, 0.0010, 0.1011, 0.0101,\n",
      "        0.0039, 0.0361, 0.0269, 0.0106, 0.0064, 0.0192, 0.0150, 0.0154, 0.0165])\n",
      "label (actual next character): 1\n",
      "probability assigned by the net to the the correct character: 0.008583184331655502\n",
      "log likelihood: -4.757950305938721\n",
      "negative log likelihood: 4.757950305938721\n",
      "--------\n",
      "bigram example 4: ma. (indexes 131,0)\n",
      "input to the neural net: [13, 1]\n",
      "output probabilities from the neural net: tensor([0.0022, 0.0559, 0.0197, 0.0135, 0.2511, 0.0113, 0.0005, 0.0019, 0.0050,\n",
      "        0.0504, 0.0294, 0.1896, 0.0405, 0.0039, 0.0021, 0.0045, 0.2022, 0.0067,\n",
      "        0.0071, 0.0092, 0.0143, 0.0120, 0.0036, 0.0435, 0.0013, 0.0071, 0.0116])\n",
      "label (actual next character): 0\n",
      "probability assigned by the net to the the correct character: 0.0021719124633818865\n",
      "log likelihood: -6.132147312164307\n",
      "negative log likelihood: 6.132147312164307\n",
      "--------\n",
      "bigram example 5: .ol (indexes 015,12)\n",
      "input to the neural net: [0, 15]\n",
      "output probabilities from the neural net: tensor([0.0048, 0.1552, 0.0311, 0.0730, 0.0087, 0.0095, 0.0117, 0.0880, 0.0026,\n",
      "        0.0193, 0.0081, 0.0223, 0.0026, 0.0006, 0.0128, 0.0767, 0.0019, 0.0035,\n",
      "        0.0403, 0.0915, 0.0371, 0.0193, 0.0278, 0.1523, 0.0559, 0.0335, 0.0096])\n",
      "label (actual next character): 12\n",
      "probability assigned by the net to the the correct character: 0.0026169309858232737\n",
      "log likelihood: -5.94575309753418\n",
      "negative log likelihood: 5.94575309753418\n",
      "=========\n",
      "average negative log likelihood, i.e. loss = 5.057831287384033\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "\n",
    "for i in range(5):\n",
    "  # i-th bigram:\n",
    "  x = xs[i] # input character index\n",
    "  y = ys[i].item() # label character index\n",
    "  ix1 = x[0].item()\n",
    "  ix2 = x[1].item()\n",
    "  print('--------')\n",
    "  print(f'bigram example {i+1}: {itos[ix1]}{itos[ix2]}{itos[y]} (indexes {ix1}{ix2},{y})')\n",
    "  print('input to the neural net:', x.tolist(   ))\n",
    "  print('output probabilities from the neural net:', prob[i])\n",
    "  print('label (actual next character):', y)\n",
    "  p = prob[i,y]\n",
    "  print('probability assigned by the net to the the correct character:', p.item())\n",
    "  logp = torch.log(p)\n",
    "  print('log likelihood:', logp.item())\n",
    "  nll = -logp\n",
    "  print('negative log likelihood:', nll.item())\n",
    "  nlls[i] = nll\n",
    "\n",
    "print('=========')\n",
    "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6962ab8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.186270713806152\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((54,27) , generator=g , requires_grad=True)\n",
    "xenc = F.one_hot(xs , num_classes=27).float()\n",
    "xenc = xenc.view(xs.shape[0], -1)\n",
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdim=True)\n",
    "loss = -prob[torch.arange(n) , ys].log().mean()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9717992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3821403980255127\n",
      "2.375330686569214\n",
      "2.3691024780273438\n",
      "2.3633830547332764\n",
      "2.358112096786499\n",
      "2.353239059448242\n",
      "2.348720073699951\n",
      "2.3445184230804443\n",
      "2.3406026363372803\n",
      "2.336944818496704\n",
      "2.3335204124450684\n",
      "2.3303089141845703\n",
      "2.327291250228882\n",
      "2.324450969696045\n",
      "2.3217737674713135\n",
      "2.3192460536956787\n",
      "2.316856622695923\n",
      "2.314594030380249\n",
      "2.3124499320983887\n",
      "2.310415029525757\n",
      "2.3084816932678223\n",
      "2.3066422939300537\n",
      "2.3048911094665527\n",
      "2.3032217025756836\n",
      "2.301628828048706\n",
      "2.300107002258301\n",
      "2.2986526489257812\n",
      "2.2972605228424072\n",
      "2.2959272861480713\n",
      "2.294649362564087\n",
      "2.2934229373931885\n",
      "2.292245388031006\n",
      "2.291114091873169\n",
      "2.2900257110595703\n",
      "2.288978099822998\n",
      "2.2879693508148193\n",
      "2.286997079849243\n",
      "2.2860591411590576\n",
      "2.285153865814209\n",
      "2.2842795848846436\n",
      "2.2834348678588867\n",
      "2.2826180458068848\n",
      "2.281827688217163\n",
      "2.281062602996826\n",
      "2.2803215980529785\n",
      "2.2796032428741455\n",
      "2.278907060623169\n",
      "2.278231382369995\n",
      "2.277575969696045\n",
      "2.2769391536712646\n",
      "2.276320695877075\n",
      "2.27571964263916\n",
      "2.275135040283203\n",
      "2.274566411972046\n",
      "2.2740135192871094\n",
      "2.27347469329834\n",
      "2.2729501724243164\n",
      "2.2724390029907227\n",
      "2.2719411849975586\n",
      "2.2714555263519287\n",
      "2.270982265472412\n",
      "2.270519971847534\n",
      "2.2700693607330322\n",
      "2.2696290016174316\n",
      "2.2691993713378906\n",
      "2.268779754638672\n",
      "2.268369436264038\n",
      "2.2679686546325684\n",
      "2.2675769329071045\n",
      "2.2671937942504883\n",
      "2.2668190002441406\n",
      "2.2664520740509033\n",
      "2.2660934925079346\n",
      "2.265742301940918\n",
      "2.2653982639312744\n",
      "2.265061616897583\n",
      "2.2647318840026855\n",
      "2.264408588409424\n",
      "2.264091968536377\n",
      "2.263781785964966\n",
      "2.2634775638580322\n",
      "2.263179302215576\n",
      "2.2628867626190186\n",
      "2.2625997066497803\n",
      "2.2623183727264404\n",
      "2.2620420455932617\n",
      "2.2617712020874023\n",
      "2.261505365371704\n",
      "2.261244058609009\n",
      "2.2609875202178955\n",
      "2.2607359886169434\n",
      "2.260488510131836\n",
      "2.2602458000183105\n",
      "2.26000714302063\n",
      "2.259772777557373\n",
      "2.259542226791382\n",
      "2.2593157291412354\n",
      "2.2590930461883545\n",
      "2.2588744163513184\n",
      "2.2586591243743896\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "    xenc = F.one_hot(xs , num_classes=27).float()\n",
    "    xenc = xenc.view(xs.shape[0], -1)\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    prob = counts / counts.sum(1 , keepdims = True)\n",
    "    loss = -prob[torch.arange(num) , ys].log().mean() \n",
    "    print(loss.item())\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -50.0*W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5bdb8425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae.\n",
      "za.\n",
      "ahallurailaziaydamellimittain.\n",
      "alayn.\n",
      "ka.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix1 = 0\n",
    "    ix2 = 0\n",
    "    while True:\n",
    "        x = torch.tensor([ix1,ix2])\n",
    "        xenc = F.one_hot( x , num_classes=27).float()\n",
    "        xenc = xenc.view(1, 54)\n",
    "        logits = xenc@W\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1 , keepdim=True)\n",
    "        ix3 = torch.multinomial(p , num_samples=1 , replacement=True , generator=g).item()\n",
    "        out.append(itos[ix3])\n",
    "        if ix3==0:\n",
    "            break\n",
    "        ix1 , ix2 = ix2 , ix3\n",
    "\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a7c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
